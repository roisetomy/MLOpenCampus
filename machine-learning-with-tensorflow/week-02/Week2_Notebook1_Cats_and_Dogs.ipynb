{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkRDoMpsfsRm"
      },
      "source": [
        "# Image Preprocessing and Binary Classification with Keras\n",
        "\n",
        "## Objective\n",
        "In this week's exercise, you will:\n",
        "1. Learn how to image preprocessing in keras.\n",
        "2. Build and train a multilayer neural network for binary classification on a real-world dataset of cats and dogs.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries\n",
        "Let's start by importing the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r2Vic2g2fsRq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOyKyiITfsRs"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Load and Preprocess the Data\n",
        "We will use the Keras `ImageDataGenerator` for image augmentation and preprocessing.\n",
        "First, unzip the uploaded dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rBm0bbwyfsRt",
        "outputId": "0d1c825b-6703-4ea0-d839-de305c6f5b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace PetImages/Cat/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "# dataset_name = \"cats_vs_dogs\"\n",
        "# (ds_train, ds_test), ds_info = tfds.load(\n",
        "#     dataset_name,\n",
        "#     split=['train[:80%]', 'train[80%:]'],  # Split into training and testing sets\n",
        "#     shuffle_files=True,\n",
        "#     as_supervised=True,  # Returns (image, label) pairs\n",
        "#     with_info=True       # Includes dataset metadata\n",
        "# )\n",
        "\n",
        "# # Explore dataset info\n",
        "# print(ds_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jwghNCNfsRu"
      },
      "source": [
        "## Step 3: Learn about undersampling and implement it\n",
        "Research online what undersampling and random undersampling is. It is a very powerful technique used often in machine Learning. Find out when it is used and undersample your dataset using \"random undersampling\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Iav8jXWfsRv",
        "outputId": "ad33286f-255e-4a7d-df19-859aab28c364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "error {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input is empty.\n",
            "\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: \n",
            "Class distribution before undersampling: Counter({1: 3664, 0: 3568})\n",
            "Class distribution after undersampling: Counter({0: 3568, 1: 3568})\n"
          ]
        }
      ],
      "source": [
        "data_dir = pathlib.Path(\"/content/PetImages\")\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "image_size = (180, 180)  # Match model input size\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# Normalize the dataset\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Collect all training images and labels for undersampling\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "try:\n",
        "    for images, labels in train_ds:\n",
        "        all_images.append(images.numpy())\n",
        "        all_labels.append(labels.numpy())\n",
        "except Exception as e:\n",
        "    print(\"error\", e)\n",
        "\n",
        "all_images = np.concatenate(all_images, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "# Display the class distribution before undersampling\n",
        "print(f\"Class distribution before undersampling: {Counter(all_labels)}\")\n",
        "\n",
        "# Flatten images for undersampling\n",
        "n_samples, height, width, channels = all_images.shape\n",
        "reshaped_images = all_images.reshape(n_samples, -1)\n",
        "\n",
        "# Perform undersampling\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "sampled_images, sampled_labels = undersampler.fit_resample(reshaped_images, all_labels)\n",
        "\n",
        "# Reshape back to image dimensions\n",
        "sampled_images = sampled_images.reshape(-1, height, width, channels)\n",
        "\n",
        "# Display the class distribution after undersampling\n",
        "print(f\"Class distribution after undersampling: {Counter(sampled_labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TmaFGcZfsRw"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 4: Set Up ImageDataGenerator (or well more specifically the new version)\n",
        "Were Sorry - the videos from the coursera course are sometimes not the most up to date. In this case the 'ImageDataGenerator' function is deprecated (look here https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) and will be removed in the future versions. The concept behind the new reccomended function is very similar though.\n",
        "The new reccomendation is loading images with tf.keras.utils.image_dataset_from_directory and transforming the output tf.data.Dataset with preprocessing layers.\n",
        "\n",
        "You may use Chat GPT for this task and you can also check the following tutorials <br>\n",
        "https://www.tensorflow.org/tutorials/load_data/images <br>\n",
        "https://www.tensorflow.org/tutorials/load_data/images <br>\n",
        "https://www.tensorflow.org/guide/keras/preprocessing_layers <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjiszColfsRw"
      },
      "outputs": [],
      "source": [
        "# TODO create a dataset using the recommended methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWdstmjhfsRx"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 5: Build a Multilayer Neural Network\n",
        "Now, let's build a multilayer neural network for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H8NRrQ4pfsRx"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(180, 180, 3)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Regularization\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHJv3lmKfsRz"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 6: Train the Model\n",
        "Train the model using the Dataset you created\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qphFzXedfsRz",
        "outputId": "d01a1824-2abb-472f-c8fb-f4ab5004270d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m  3/223\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:58\u001b[0m 4s/step - accuracy: 0.5069 - loss: 39.0487"
          ]
        }
      ],
      "source": [
        "model.fit(sampled_images, sampled_labels, epochs=10, batch_size=batch_size, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1eaOqtfsR0"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 7: Evaluate the Model\n",
        "After training, you may upload some test images to evaluate your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtpNV_apfsR0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "def load_and_predict(model):\n",
        "    uploaded_files = files.upload()\n",
        "\n",
        "    for fn in uploaded_files.keys():\n",
        "        path = '/content/' + fn\n",
        "        img = image.load_img(path, target_size=(150, 150))\n",
        "\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0) / 255.0\n",
        "\n",
        "        classes = model.predict(x)\n",
        "        result = \"a dog\" if classes[0] > 0.5 else \"a cat\"\n",
        "\n",
        "        print(f'The model predicts that the image is of {result}')\n",
        "\n",
        "# Call the function to upload images and get predictions\n",
        "load_and_predict(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".ve_tensorflow_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}